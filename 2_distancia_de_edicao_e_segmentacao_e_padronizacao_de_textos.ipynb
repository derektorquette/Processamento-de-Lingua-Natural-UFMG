{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqmSWjVDjPiTCEeVFl693C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/derektorquette/processamento-de-lingua-natural-ufmg/blob/main/2_distancia_de_edicao_e_segmentacao_e_padronizacao_de_textos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DISTÂNCIA DE LEVENSHTEIN - EXEMPLO 1**"
      ],
      "metadata": {
        "id": "6huuaNxUEzsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import editdistance\n",
        "\n",
        "a = \"Bello Horizonte\"\n",
        "b = \"Belo Horizonte\"\n",
        "\n",
        "distancia = editdistance.eval(a, b)\n",
        "\n",
        "print ( \"A distância de Levenshtein entre\", a, \"e\", b, \"é igual a\", distancia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv-BB6BAChSx",
        "outputId": "d0353b91-2df5-4a74-8560-1bdfdd63ddc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A distância de Levenshtein entre Bello Horizonte e Belo Horizonte é igual a 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DISTÂNCIA DE LEVENSHTEIN COM NLTK**"
      ],
      "metadata": {
        "id": "9g87yJq1E9UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import *\n",
        "\n",
        "a = \"Bello Horizzonte\"\n",
        "b = \"Belo Horizonte\"\n",
        "\n",
        "distancia = edit_distance(a,b)\n",
        "\n",
        "print(\"A Distância de Levenshtein entre\", a, \"e\", b, \"é igual a\", distancia)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMCZWlf6EsLH",
        "outputId": "ac255185-31ed-4cff-f80d-5c53daed41e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Distância de Levenshtein entre Bello Horizzonte e Belo Horizonte é igual a 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SUBSTITUIÇÃO**"
      ],
      "metadata": {
        "id": "n_yhKkFTFwC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import *\n",
        "\n",
        "a = \"Minnas Geraes\"\n",
        "b = \"Minas Gerais\"\n",
        "\n",
        "distancia = edit_distance(a,b, substitution_cost= 2)\n",
        "\n",
        "print(\"A distância de Levenshtein com substituição entre\", a, \"e\", b, \"é igual a\", distancia)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lHUkCz8Gf4l",
        "outputId": "c2b20b11-2394-42e5-e3da-f0f77f9a416d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A distância de Levenshtein com substituição entre Minnas Geraes e Minas Gerais é igual a 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**EXEMPLO DE CORRETOR ORTOGRÁFICO**"
      ],
      "metadata": {
        "id": "InlUHRs7NbXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import words\n",
        "\n",
        "# Baixe os recursos necessários da NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "\n",
        "# Lista de palavras reconhecidas\n",
        "palavras_reconhecidas = {\"O\", \"A\", \"Os\", \"As\", \"homem\", \"homens\", \"mulher\", \"mulheres\", \"é\", \"são\", \"inteligente\", \"inteligentes\", \"brilhante\", \"brilhantes\"}\n",
        "\n",
        "def corretor_ortografico(frase):\n",
        "    # Tokenize a frase em palavras\n",
        "    tokens = word_tokenize(frase.lower())  # Converter para minúsculas para tornar a comparação de palavras insensível a maiúsculas e minúsculas\n",
        "\n",
        "    # Verifique cada palavra na frase e corrija-a se necessário\n",
        "    correcoes = []\n",
        "    for token in tokens:\n",
        "        if token not in palavras_reconhecidas and token not in words.words():\n",
        "            sugestoes = corrigir_palavra(token)\n",
        "            correcoes.extend(sugestoes)  # Estender a lista de correções com as sugestões\n",
        "        else:\n",
        "            correcoes.append(token)\n",
        "\n",
        "    # Reconstrua a frase corrigida\n",
        "    frase_corrigida = ' '.join(correcoes)\n",
        "\n",
        "    return frase_corrigida\n",
        "\n",
        "def corrigir_palavra(palavra):\n",
        "    # Se a palavra estiver incorreta, encontre sugestões de correção usando a distância de edição mínima\n",
        "    sugestoes = []\n",
        "    for palavra_reconhecida in palavras_reconhecidas:\n",
        "        if nltk.edit_distance(palavra, palavra_reconhecida) == 1:\n",
        "            sugestoes.append(palavra_reconhecida)\n",
        "\n",
        "    if not sugestoes:\n",
        "        sugestoes.append(palavra)  # Se nenhuma sugestão for encontrada, mantenha a palavra original\n",
        "\n",
        "    return sugestoes\n",
        "\n",
        "# Exemplo de uso\n",
        "frase = \"as muleres são brilantes\"\n",
        "frase_corrigida = corretor_ortografico(frase)\n",
        "print(\"Frase corrigida:\", frase_corrigida)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7IeOuslM8JH",
        "outputId": "d2cedd91-8b56-46d9-af35-6a6698df51ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase corrigida: as mulheres são brilhantes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**TOKENIZAÇÃO E CAPITALIZAÇÃO (EXEMPLO DE CAPITALIZAÇÃO NO COMENTÁRIO)**"
      ],
      "metadata": {
        "id": "rUMI4zq4VVmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk.download ('punkt')\n",
        "from nltk import tokenize\n",
        "\n",
        "versos = \"\"\"No meio do caminho tinha uma pedra\n",
        "tinha uma pedra no meio do caminho. Guarda-chuva para chuva\"\"\"\n",
        "\n",
        "# para tansformar em minusculas, usar \"versos.lower()\"\n",
        "\n",
        "palavras = tokenize.word_tokenize(versos, language='portuguese')\n",
        "\n",
        "print(len(palavras), palavras, '\\n', len(set(palavras)), set(palavras))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7ryFw4VU0h",
        "outputId": "5ca8f05d-5600-447d-ff1e-94efd757ed7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 ['No', 'meio', 'do', 'caminho', 'tinha', 'uma', 'pedra', 'tinha', 'uma', 'pedra', 'no', 'meio', 'do', 'caminho', '.', 'Guarda-chuva', 'para', 'chuva'] \n",
            " 12 {'Guarda-chuva', 'meio', 'no', 'tinha', 'pedra', 'uma', 'caminho', '.', 'do', 'chuva', 'para', 'No'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEMATIZAÇÃO**\n",
        "\n"
      ],
      "metadata": {
        "id": "SPpAVQVibAOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print (\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print (\"corpora:\", lemmatizer.lemmatize(\"corpora\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IItdNIwbF8i",
        "outputId": "4bb57ff4-178b-4c77-b098-39aaf20ab570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora: corpus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEMATIZAÇÃO USANDO O SPACY**"
      ],
      "metadata": {
        "id": "8sJbU458cfqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!pip install -U spacy-lookups-data\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "id": "kejLghYPcllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "pln = spacy.load('pt_core_news_sm')\n",
        "\n",
        "frase = pln(\"A comida estava gostosa. Todos comeram e gostaram.\")\n",
        "\n",
        "lemas = []\n",
        "for token in frase:\n",
        "  lema = token.lemma_\n",
        "  lemas.append(lema)\n",
        "\n",
        "print(lemas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDEQ6HjUd1tC",
        "outputId": "5f0c14a8-844f-4c74-c850-a2c6f7cdf9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['o', 'comida', 'estar', 'gostoso', '.', 'todo', 'comer', 'e', 'gostar', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**RADICALIZAÇÃO (STEMMING) - REMOÇÃO DE SUFIXOS**\n",
        "\n"
      ],
      "metadata": {
        "id": "fX6gODPPe4UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "raiz = nltk.stem.RSLPStemmer()\n",
        "\n",
        "print(raiz.stem(\"a\"),\n",
        "      raiz.stem(\"comida\"),\n",
        "      raiz.stem(\"gostaram\"))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F8PB-RxNe8af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SEGMENTAÇÃO DE FRASES**\n",
        "\n"
      ],
      "metadata": {
        "id": "Vpu3fuRrgO6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "frases = nltk.data.load('tokenizers/punkt/portuguese.pickle')\n",
        "\n",
        "musica_jorgeben = \"\"\"Para que meus inimigos\n",
        "Tenham mãos e não me toquem\n",
        "Para que meus inimigos\n",
        "Tenham pés e não me alcancem\"\"\"\n",
        "\n",
        "frases.tokenize(musica_jorgeben)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQuZmJ8CgOmy",
        "outputId": "69d0926f-7318-4b6e-f2ba-5cff1f7378df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Para que meus inimigos\\nTenham mãos e não me toquem\\nPara que meus inimigos\\nTenham pés e não me alcancem']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}